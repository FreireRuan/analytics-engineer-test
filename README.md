# Desafio TÃ©cnico - Analytics Engineer

SoluÃ§Ã£o desenvolvida para o teste tÃ©cnico de Analytics Engineer

---

## ğŸ¯ NavegaÃ§Ã£o RÃ¡pida

| ExercÃ­cio | DescriÃ§Ã£o | Arquivo |
|-----------|---------------|---------|
| **1 - SQL** | Queries analÃ­ticas | [`exercicio_1.sql`](./exercicio_1.sql) |
| **2 - ETL** | Script PySpark | [`exercicio_2_etl.py`](./exercicio_2_etl.py) |
| **2 - DDL** | Estrutura da tabela | [`exercicio_2_ddl.sql`](./exercicio_2_ddl.sql) |
| **2 - Dataset** | Exemplo populado | [`exercicio_2_dataset_exemplo.md`](./exercicio_2_dataset_exemplo.md) |
| **2 - Queries** | Consultas GMV | [`exercicio_2_queries_gmv.sql`](./exercicio_2_queries_gmv.sql) |
| **2 - Tech Stack** | Arquitetura | [`exercicio_2_tech_stack.md`](./exercicio_2_tech_stack.md) |

---

## ğŸ“ ExercÃ­cio 1 - SQL

**Arquivo:** [`exercicio_1.sql`](./exercicio_1.sql)

Queries para responder Ã s perguntas do desafio:

| # | Pergunta | TÃ©cnica utilizada |
|---|----------|-------------------|
| 1 | Quais sÃ£o os 50 maiores produtores em faturamento de 2021? | CTE + `ROW_NUMBER()` |
| 2 | Quais sÃ£o os 2 produtos que mais faturaram de cada produtor? | CTE + `ROW_NUMBER()` com `PARTITION BY` |

---

## ğŸ”„ ExercÃ­cio 2 - Modelagem e Desenvolvimento GMV

### Contexto

O objetivo Ã© calcular o **GMV (Gross Merchandising Value)** diÃ¡rio por subsidiÃ¡ria, com uma modelagem que:
- Preserve o histÃ³rico de forma imutÃ¡vel
- Permita navegaÃ§Ã£o temporal
- Facilite a recuperaÃ§Ã£o de dados correntes

### Regra de NegÃ³cio

```
GMV = SUM(product_item.purchase_value)
WHERE purchase.release_date IS NOT NULL
```

### EntregÃ¡veis

#### 1ï¸âƒ£ Script ETL â†’ [`exercicio_2_etl.py`](./exercicio_2_etl.py)

Pipeline em Python/PySpark que:
- LÃª eventos CDC das tabelas `purchase`, `product_item` e `purchase_extra_info`
- Aplica deduplicaÃ§Ã£o mantendo registros mais recentes
- Calcula GMV diÃ¡rio por subsidiÃ¡ria
- Implementa versionamento SCD Type 2

#### 2ï¸âƒ£ DDL da Tabela Final â†’ [`exercicio_2_ddl.sql`](./exercicio_2_ddl.sql)

Estrutura da tabela `gmv_historico_subsidiaria` com:
- Campos de negÃ³cio (reference_date, subsidiary, gmv_daily)
- Campos de controle SCD Type 2 (valid_from, valid_to, is_current)
- Particionamento por snapshot_date

#### 3ï¸âƒ£ Dataset Exemplo â†’ [`exercicio_2_dataset_exemplo.md`](./exercicio_2_dataset_exemplo.md)

DemonstraÃ§Ã£o completa com:
- Dados de entrada (conforme PDF do desafio)
- LÃ³gica de deduplicaÃ§Ã£o aplicada
- Resultado final da tabela GMV

#### 4ï¸âƒ£ Queries GMV â†’ [`exercicio_2_queries_gmv.sql`](./exercicio_2_queries_gmv.sql)

Consultas SQL incluindo:
- **Query principal**: GMV diÃ¡rio por subsidiÃ¡ria (dados correntes)
- NavegaÃ§Ã£o temporal entre snapshots
- ValidaÃ§Ã£o de integridade

#### 5ï¸âƒ£ Tech Stack â†’ [`exercicio_2_tech_stack.md`](./exercicio_2_tech_stack.md)

DocumentaÃ§Ã£o da arquitetura:
- Modelo de dados fonte
- Componentes da stack (Spark, Delta Lake, Airflow)
- Justificativas tÃ©cnicas

---

## ğŸ—ï¸ Arquitetura Resumida

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  purchase   â”‚    â”‚product_item â”‚    â”‚ extra_info  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚                  â”‚                  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Apache Spark  â”‚
                 â”‚   (PySpark)    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚gmv_historico_  â”‚
                 â”‚  subsidiaria   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Modelagem SCD Type 2

| Requisito | Como foi implementado |
|-----------|----------------------|
| Imutabilidade | Campos `valid_from` e `valid_to` |
| NavegaÃ§Ã£o temporal | Filtros por perÃ­odo de validade |
| Dados correntes | Flag `is_current = TRUE` |
| Rastreabilidade | PartiÃ§Ã£o por `snapshot_date` |

---

## ğŸ› ï¸ Tech Stack

| Componente | Tecnologia |
|------------|------------|
| ETL Engine | Apache Spark (PySpark) |
| Linguagem | Python |
| Armazenamento | Delta Lake / Parquet |
| OrquestraÃ§Ã£o | Apache Airflow |
| Cloud | AWS |

Detalhes em [`exercicio_2_tech_stack.md`](./exercicio_2_tech_stack.md).
